[
  {
    "objectID": "Practical.html",
    "href": "Practical.html",
    "title": "2  Practical",
    "section": "",
    "text": "3 Question 1\nShown below are summary statistics (mean and variance) of 100 samples from an exponential distribution of mean via via use of the foreach package.\n\n#Loop\nresults &lt;- foreach(i = 1:100 ,.combine = rbind ) %do% {\n  vals &lt;- rexp(100,1)\n  c(mean(vals), var(vals))\n  \n}\n\n\nresults |&gt; \n  data.frame() |&gt; \n  tibble::remove_rownames() |&gt; \n  knitr::kable(col.names = c(\"Means\", \"Variances\"), digits = 3)\n\n\n\n\nMeans\nVariances\n\n\n\n\n1.035\n0.844\n\n\n0.895\n0.570\n\n\n1.021\n0.861\n\n\n0.913\n0.738\n\n\n0.880\n0.608\n\n\n0.909\n1.134\n\n\n0.899\n0.671\n\n\n0.952\n1.069\n\n\n0.941\n0.657\n\n\n1.092\n1.056\n\n\n1.071\n1.207\n\n\n1.077\n0.820\n\n\n0.975\n1.036\n\n\n0.946\n0.659\n\n\n1.184\n1.468\n\n\n0.940\n0.907\n\n\n0.886\n0.797\n\n\n1.013\n0.900\n\n\n1.018\n0.952\n\n\n1.053\n1.118\n\n\n0.902\n0.753\n\n\n0.990\n0.904\n\n\n1.185\n1.336\n\n\n1.125\n0.894\n\n\n1.024\n0.904\n\n\n0.987\n0.907\n\n\n1.008\n0.695\n\n\n0.855\n0.749\n\n\n0.888\n0.579\n\n\n0.947\n0.779\n\n\n0.913\n0.844\n\n\n1.021\n0.748\n\n\n0.868\n0.615\n\n\n0.770\n0.720\n\n\n1.137\n1.606\n\n\n0.985\n1.389\n\n\n1.239\n1.531\n\n\n0.954\n0.586\n\n\n0.904\n0.773\n\n\n0.888\n0.625\n\n\n0.951\n0.948\n\n\n0.825\n0.772\n\n\n1.025\n0.906\n\n\n0.881\n1.134\n\n\n1.082\n1.298\n\n\n0.996\n1.320\n\n\n0.843\n1.038\n\n\n1.056\n0.796\n\n\n0.912\n0.771\n\n\n1.124\n1.357\n\n\n0.757\n0.512\n\n\n0.914\n0.434\n\n\n1.110\n1.377\n\n\n1.106\n1.090\n\n\n1.162\n1.146\n\n\n0.981\n1.108\n\n\n0.832\n0.554\n\n\n0.990\n1.056\n\n\n0.972\n0.813\n\n\n0.878\n0.802\n\n\n1.003\n0.945\n\n\n0.910\n0.954\n\n\n0.943\n0.851\n\n\n1.094\n0.943\n\n\n1.067\n1.114\n\n\n1.062\n1.402\n\n\n1.125\n1.334\n\n\n0.928\n0.823\n\n\n1.085\n1.704\n\n\n1.027\n1.109\n\n\n1.019\n1.046\n\n\n1.013\n1.252\n\n\n1.095\n1.242\n\n\n1.044\n1.166\n\n\n1.114\n1.117\n\n\n0.823\n0.728\n\n\n0.988\n0.992\n\n\n0.886\n0.660\n\n\n0.849\n0.487\n\n\n1.173\n1.340\n\n\n0.981\n0.677\n\n\n1.068\n1.194\n\n\n0.938\n0.849\n\n\n0.883\n0.943\n\n\n1.191\n1.239\n\n\n0.954\n0.977\n\n\n1.025\n1.048\n\n\n1.144\n1.294\n\n\n1.008\n0.750\n\n\n1.117\n0.879\n\n\n1.108\n1.254\n\n\n0.928\n0.822\n\n\n1.229\n1.398\n\n\n0.936\n0.815\n\n\n1.035\n0.993\n\n\n0.867\n0.597\n\n\n1.016\n1.129\n\n\n1.056\n1.081\n\n\n0.907\n0.816\n\n\n1.083\n1.418\n\n\n\n\n\n\n\n4 Question 2\nBelow is a useful function that will format and display neat tables presenting the results.\n\n#Function that takes system time results and prints an interpretable table\ntablefy &lt;- function(d, heading) {\ndata.frame(d)[1:3,] |&gt; \n  t() |&gt; \n  knitr::kable(col.names = c(\"User time\", \"System Time\", \"Total elapsed\"), caption = heading)\n}\n\nBelow are serial and parallel bootstrapping computations of 1 sample at a time each of size 1000.\n\ngal &lt;- galaxies\n\n#1 Bootstrap sample of 1000 at a time\n\n#Serial \ntablefy(\n  system.time(\n    result1 &lt;- foreach(i = 1:100000, .combine = c ) %do% {\n      res &lt;- sample(gal, replace = TRUE)\n      median(res)\n    }\n  ), \n  \"Serial single sample bootstrap\"\n)\n\n\nSerial single sample bootstrap\n\n\nUser time\nSystem Time\nTotal elapsed\n\n\n\n\n6.277\n0.054\n6.338\n\n\n\n\n#Parallel\n\ncl &lt;- makeCluster(10)\nregisterDoParallel(cl)\n\ntablefy(\n  system.time(\n    result2 &lt;- foreach(i = 1:100000, .combine = c ) %dopar% {\n      res &lt;- sample(gal, replace = TRUE)\n      median(res)\n    }\n  ), \n  \"Parallel single sample bootstrap\"\n)\n\n\nParallel single sample bootstrap\n\n\nUser time\nSystem Time\nTotal elapsed\n\n\n\n\n8.018\n0.615\n8.651\n\n\n\n\nstopCluster(cl)\n\nClearly the use of parallelisation did not result in a more efficient computation, there was little to not difference in the user (CPU) time but there was in increase in system (OS) time, likely due to task scheduling of the parallel tasks. Clearly in this case parallelising the computation did not result in any efficiency, it is likely that the quantity of data that had to be returned was not large enough to justify the use of parallel computing, this idea is explored below.\nBelow are serial and parallel bootstraps of 1000 samples at a time, each of size 1000.\n\n#1 00 bootstrap samples of 1000 at a time \n\n\n#Serial \ntablefy(\n  system.time(\n    result1 &lt;- foreach(i = 1:1000, .combine = c ) %do% {\n      inner &lt;- foreach(j = 1:1000, .combine = c) %do% {\n        res &lt;- sample(gal, replace = TRUE)\n        median(res)\n      }\n      inner\n    }\n  ), \"Serial bootstrap of 1000 samples\" \n)\n\n\nSerial bootstrap of 1000 samples\n\n\nUser time\nSystem Time\nTotal elapsed\n\n\n\n\n65.171\n0.491\n65.67\n\n\n\n\n#Parallel\n\ncl &lt;- makeCluster(10)\nregisterDoParallel(cl)\n\ntablefy(system.time(\n  result2 &lt;- foreach(i = 1:1000, .combine = rbind, .packages = 'foreach' ) %dopar% {\n    inner &lt;- foreach(j = 1:1000, .combine = c, .packages = 'foreach') %dopar% {\n    res &lt;- sample(gal, replace = TRUE)\n    median(res)\n    }\n    return(inner)\n  }\n), \"Parallel bootstrap of 1000 samples\"\n)\n\n\nParallel bootstrap of 1000 samples\n\n\nUser time\nSystem Time\nTotal elapsed\n\n\n\n\n0.268\n0.1\n10.827\n\n\n\n\nstopCluster(cl)\n\nClearly the use of parallel computing resulting in a much faster computation and leads one ot believe that it would provide efficiency in a situation where the quantity of data that needs to be returned is large.\n\n\n5 Question 3\nBelow we estimate the coverage of a percentile bootstrap confidence interval for samples of size 50 from an exponential distribution of mean 1.\nThis will be implemented by generating 500 samples of size 10000 from the exponential distribution with mean 1. For each of these samples a 500 bootstrapped mean estimates will be sampled. For each of the 500 samples a 95% percentile bootstrap confidence interval of the mean will be generated. It will be thereafter be recorded as to whether 1 lies inside each of these intervals, the proportion of intervals than contain 1 will be the estimated coverage\nThe result is shown below.\n\ncl &lt;- makeCluster(10)\nregisterDoParallel(cl)\n\n\n#Generate exponential sample \n\n\ninCi &lt;- foreach(i = 1:500, .combine = c, .packages = 'foreach') %dopar%{\n  smpl_init &lt;- rexp(10000, rate = 1)\n  means &lt;- foreach(i = 1:500, .combine = c, .packages = 'foreach') %dopar% {\n    bsampls &lt;- sample(smpl_init, replace = T)\n    return(mean(bsampls))\n  }\n  \n  quants &lt;- quantile(means, probs = c(0.025, 0.975))\n  \n  return(((quants[1] &lt;= 1) && (quants[2] &gt;= 1)))\n}\n\npaste0(mean(inCi)*100, \"%\") |&gt; \n  knitr::kable(col.names = \"Estimated Coverage\")\n\n\n\n\nEstimated Coverage\n\n\n\n\n93.8%\n\n\n\n\nstopCluster(cl)\n\nThe estimated coverage is shown in the table above, this is not a surprising figure as each bootstrap percentile confidence interval is a 95% confidence interval.\n\n\n6 Question 4\nBelow is a serial iteration over 3 vectors each containing 5 random variables and finds the max of those vectors. It is parallel safe and on a larger scale can easily be parallelised to provide more computationally efficient solutions.\n\n#Set seed for reproducibility\nset.seed(1234)  \n\nmaxes &lt;- foreach(i = 1:3, .combine = c, .packages = \"iterators\") %do% {\n  it2 &lt;- irnorm(1)  \n  max &lt;- foreach(j = 1:5, .combine = c) %do% {\n    nextElem(it2)\n  }\n  max(max)\n}\n\nmaxes |&gt; \n  t() |&gt; \n  knitr::kable(caption = \"Serially computed maximums of Normal random vectors\", digits = 3)\n\n\nSerially computed maximums of Normal random vectors\n\n\n1.084\n0.506\n0.959\n\n\n\n\n\n\n\n7 Question 5\nBelow a run time comparison is given for the performance of the parLapply, foreach and replicate functions for the previous problem.\n\n#foreach\n\n# Set up parallel cluster\ncl &lt;- makeCluster(4)\nregisterDoParallel(cl)\n\n#Setting seed in parallel safe way\n  \n\n# Parallel computation of maximums\ntablefy(\n  system.time(\n    maxes &lt;- foreach(i = 1:3, .combine = c, .packages = c(\"iterators\", \"foreach\")) %dopar% {\n    it2 &lt;- irnorm(1)  \n    max_val &lt;- foreach(j = 1:5, .combine = c, .packages = \"foreach\") %do% {  \n      nextElem(it2)\n    }\n    max(max_val)\n  }),\n\"foreach run time\"\n)\n\n\nforeach run time\n\n\nUser time\nSystem Time\nTotal elapsed\n\n\n\n\n0.002\n0\n0.015\n\n\n\n\n# Stop cluster\nstopCluster(cl)\n\n\n#Function f that takes 5 normal draws from an irnorm iterator and finds the max of these draws\n\nf &lt;- function(x){\n  library(iterators)\n  it &lt;- irnorm(1)\n  elements &lt;- sapply(1:5, function(y) nextElem(it))\n  max(elements)\n  \n}\n\ncl &lt;- makeCluster(10)\n\n\ntablefy(system.time(maxlist &lt;- parLapply(cl, 1:3, f)), \"parLapply run time\")\n\n\nparLapply run time\n\n\nUser time\nSystem Time\nTotal elapsed\n\n\n\n\n0.001\n0\n0.004\n\n\n\n\nstopCluster(cl)\n\n\n#Function f that takes 5 normal draws from an irnorm iterator and finds the max of these draws\nf &lt;- function(x){\n  it &lt;- irnorm(1)\n  elements &lt;- sapply(1:5, function(y) nextElem(it))\n  max &lt;- max(elements)\n}\n\n\n\ntablefy(system.time(maxlist &lt;- replicate(3, f(1))), \"replicate run time\")\n\n\nreplicate run time\n\n\nUser time\nSystem Time\nTotal elapsed\n\n\n\n\n0.002\n0\n0.001\n\n\n\n\n\nClearly the parLapply function is superior as its runtime is so low that it registers as 0.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home Page",
    "section": "",
    "text": "This practical concerns involves several calculations concering the parallelising of tasks in the R environment.\nBelow is the link to my GitHub repository containing the practical.\nhttps://github.com/CormacTredoux/Practical1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home Page</span>"
    ]
  }
]